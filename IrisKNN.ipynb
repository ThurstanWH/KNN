{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IrisKNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUk5LtoBSz6q"
      },
      "source": [
        "# Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBADlbImO7xO",
        "outputId": "e4b602b2-07b5-4c3e-b961-1a5717c1bc2d"
      },
      "source": [
        "# import modules\n",
        "from sklearn import datasets \n",
        "import numpy as np \n",
        "import math\n",
        "\n",
        "# set the seed for the random number generator\n",
        "mySeed=1234567\n",
        "\n",
        "# load data\n",
        "iris = datasets.load_iris() # load data \n",
        "X = iris.data # get features\n",
        "y = iris.target # get targets\n",
        "print(iris.DESCR) # print dataset description\n",
        "print(X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfZp8MPPS8vr"
      },
      "source": [
        "# KNN Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9tm90N4Pu61"
      },
      "source": [
        "def distEuclid(x1,x2):\n",
        "  '''\n",
        "  returns the euclidean distance between x1 and x2\n",
        "  '''\n",
        "  dist = 0.0\n",
        "  for dim in range(len(x1)):\n",
        "    dist += (x1[dim] - x2[dim]) ** 2\n",
        "  return math.sqrt(dist)\n",
        "\n",
        "def distManhattan(x1,x2):\n",
        "  '''\n",
        "  returns the manhattan distance between x1 and x2\n",
        "  '''\n",
        "  dist = 0.0\n",
        "  for dim in range(len(x1)):\n",
        "    dist += abs(x1[dim] - x2[dim])\n",
        "  return dist\n",
        "\n",
        "def distMinkowski(x1,x2):\n",
        "  '''\n",
        "  returns the minkowski distance between x1 and x2\n",
        "  '''\n",
        "  dist = 0.0\n",
        "  for dim in range(len(x1)):\n",
        "    dist += abs(x1[dim] - x2[dim]) ** 3\n",
        "  return dist ** (1/3)\n",
        "\n",
        "def findNearest(X,x_,k,distType):\n",
        "  '''\n",
        "  takes training data X, and sample data x_ to find the k nearest neighbours to x_ in X using distance function distType\n",
        "  '''\n",
        "  dists = list()#list of distances between x_ and every value in X\n",
        "  nearest = list()#list of x_'s k nearest neighbours in X\n",
        "  #inserts the index of x in X and the distance (defined by distType) between x and x_ into the dists list\n",
        "  if distType == 'euclidean':\n",
        "    for i in range(len(X)):\n",
        "      dists.append((i, distEuclid(X[i],x_)))\n",
        "  elif distType == 'manhattan':\n",
        "    for i in range(len(X)):\n",
        "      dists.append((i, distManhattan(X[i],x_)))\n",
        "  elif distType == 'minkowski':\n",
        "    for i in range(len(X)):\n",
        "      dists.append((i, distMinkowski(X[i],x_)))\n",
        "  dists.sort(key=lambda tup: tup[1])#sorts the dists list with in ascending order of distance to x_\n",
        "  for i in range(k):#inserts the k nearest neighbours into the nearest list\n",
        "    nearest.append(dists[i])\n",
        "  return nearest\n",
        "\n",
        "def predictClass(X,y,x_,k,distType,c):\n",
        "  '''\n",
        "  Takes training data X, training outputs y, sample x_ then returns the predicted class of the sample\n",
        "  '''\n",
        "  nearest = findNearest(X,x_,k,distType)#list of x_'s k nearest neighbours in X\n",
        "  count = list()#list where each index represents a class in X\n",
        "  for i in range(c):\n",
        "    count.append(0)\n",
        "  for i in range(k):\n",
        "    count[y[nearest[i][0]]] += 1 #increment the value in count at index y for each label y corresponding to neighbor x in X\n",
        "  max = 0\n",
        "  maxI = 0\n",
        "  for  i in range(c):#find the most commonly occuring class among the nearest neighbours to x_\n",
        "    if count[i] > max:\n",
        "      max = count[i]\n",
        "      maxI = i\n",
        "  return maxI\n",
        "\n",
        "\n",
        "\n",
        "def mykNN(X,y,X_,k,distType,c):\n",
        "  '''\n",
        "  Takes training data X, training outputs y, testing data X_ then returns the predicted outputs for X_\n",
        "  k is the number of neighbours and distType is the distance type\n",
        "  c is the number of classes in the data\n",
        "  '''\n",
        "  y_ = list()\n",
        "  for sample in X_:\n",
        "    y_.append(predictClass(X,y,sample,k,distType,c))\n",
        "  return y_\n",
        "\n",
        "def getAccuracy(trainX,trainy,valX,valy,k,distType,c):\n",
        "  '''\n",
        "  takes training and validation data to find kNN accuracy using k nearest neighboours and distance funstion distType\n",
        "  '''\n",
        "  y_ = mykNN(trainX,trainy,valX,k,distType,c)\n",
        "  correct = 0\n",
        "  for i in range(len(y_)):\n",
        "    if y_[i] == valy[i]:\n",
        "      correct += 1\n",
        "  return (correct/len(y_))*100\n",
        "\n",
        "def myNestedCrossVal(X,y,N,K,distTypes,mySeed,c):\n",
        "  '''\n",
        "  takes dataset X and corresponding labels y and performs N-fold cross validation on all k in K and all distance functions in distType\n",
        "  returns a list containing the accuracy of the best parameters in each fold as well as a list describing those parameters\n",
        "  '''\n",
        "  accuracies_fold = list()\n",
        "  best_parameters_fold = list()\n",
        "  np.random.seed(mySeed)\n",
        "  np.random.shuffle(X)\n",
        "  np.random.seed(mySeed)\n",
        "  np.random.shuffle(y)\n",
        "  splitX = np.array_split(X,N)#splits X into n arrays stored in splitX\n",
        "  splity = np.array_split(y,N)#splits y into n arrays stored in splity\n",
        "  for n in range(N):\n",
        "    #split data into a testing set, a training set, and a validation set\n",
        "    testX = splitX[n]\n",
        "    trainX = splitX[:n] + splitX[n+1:]\n",
        "    valX = trainX[N-2]\n",
        "    trainX = np.concatenate(trainX[:N-2])\n",
        "    testy = splity[n]\n",
        "    trainy = splity[:n] + splity[n+1:]\n",
        "    valy = trainy[N-2]\n",
        "    trainy = np.concatenate(trainy[:N-2])\n",
        "    accuracyMax = [0.0,0,'']\n",
        "    for k in K:\n",
        "      for distType in distTypes:\n",
        "        accuracy = getAccuracy(trainX,trainy,valX,valy,k,distType,c)#find the accuracy of this fold for every value of k and disttype\n",
        "        if accuracy > accuracyMax[0]:\n",
        "          accuracyMax = [accuracy,k,distType]#store the accuracy and details of the best performing parameters of this fold\n",
        "    accuracies_fold.append(getAccuracy(np.concatenate((trainX,valX)),np.concatenate((trainy,valy)),testX,testy,accuracyMax[1],accuracyMax[2],c))#test the best performing parameters from this fold on the test data\n",
        "    best_parameters_fold.append((accuracyMax[1],accuracyMax[2]))\n",
        "  return accuracies_fold, best_parameters_fold"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF6EVbyoTiMH"
      },
      "source": [
        "# KNN test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZllcSaTRyYC",
        "outputId": "e68d63e9-9b4d-4bb6-ed03-a634c0c46b98"
      },
      "source": [
        "#KNN tested on dataset\n",
        "accuracies_fold, best_parameters_fold = myNestedCrossVal(X,y,5,list(range(1,11)),['euclidean','manhattan', 'minkowski'],mySeed,3)\n",
        "for i in range(len(accuracies_fold)):\n",
        "  print('fold: ' + str(i + 1) + ' accuracy: ' + str(accuracies_fold[i]) + ' k: ' + str(best_parameters_fold[i][0]) + ' distance: ' + best_parameters_fold[i][1])\n",
        "\n",
        "\n",
        "#KNN tested on dataset with added noise\n",
        "np.random.seed(mySeed) \n",
        "XN=X+np.random.normal(0,0.5,X.shape)\n",
        "accuracies_fold, best_parameters_fold = myNestedCrossVal(XN,y,5,list(range(1,11)),['euclidean','manhattan', 'minkowski'],mySeed,3)\n",
        "for i in range(len(accuracies_fold)):\n",
        "  print('fold: ' + str(i + 1) + ' accuracy: ' + str(accuracies_fold[i]) + ' k: ' + str(best_parameters_fold[i][0]) + ' distance: ' + best_parameters_fold[i][1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold: 1 accuracy: 96.66666666666667 k: 4 distance: euclidean\n",
            "fold: 2 accuracy: 93.33333333333333 k: 4 distance: euclidean\n",
            "fold: 3 accuracy: 93.33333333333333 k: 1 distance: euclidean\n",
            "fold: 4 accuracy: 100.0 k: 4 distance: euclidean\n",
            "fold: 5 accuracy: 96.66666666666667 k: 1 distance: euclidean\n",
            "fold: 1 accuracy: 96.66666666666667 k: 1 distance: manhattan\n",
            "fold: 2 accuracy: 80.0 k: 3 distance: minkowski\n",
            "fold: 3 accuracy: 86.66666666666667 k: 10 distance: euclidean\n",
            "fold: 4 accuracy: 80.0 k: 3 distance: euclidean\n",
            "fold: 5 accuracy: 83.33333333333334 k: 2 distance: euclidean\n"
          ]
        }
      ]
    }
  ]
}